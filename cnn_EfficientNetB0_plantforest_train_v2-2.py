import os
import shutil
import json
import kagglehub
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models

# -----------------------------------------------------------
# 0. ì„¤ì •
# -----------------------------------------------------------
USE_FILTERED_CLASSES = False
ALLOWED_CLASSES = ["Healthy Wheat", "Leaf Blight", "Stem fly"]
SPLIT_FOLDERS = ["train", "validation"]

# âœ… [ìˆ˜ì •ë¨] ë¡œì»¬ ì €ì¥ ê²½ë¡œ ì„¤ì • (í˜„ì¬ í´ë” ê¸°ì¤€ 'models' í´ë”ì— ì €ì¥)
BASE_DIR = os.getcwd()
MODEL_SAVE_DIR = os.path.join(BASE_DIR, "my_models")
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

CKPT_PATH = os.path.join(MODEL_SAVE_DIR, "efficientnet_v2_s_plantforestdisease.pt")
CLASS_PATH = os.path.join(MODEL_SAVE_DIR, "efficientnet_v2_s_plantforestdisease.json")

# âœ… [ìˆ˜ì •ë¨] ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ (ë¡œì»¬ GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆí•˜ì„¸ìš”. OOM ì—ëŸ¬ë‚˜ë©´ 8ë¡œ ì¤„ì´ì„¸ìš”)
BATCH_SIZE = 32   
NUM_WORKERS = 0   # ìœˆë„ìš° ë¡œì»¬ì—ì„œëŠ” ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
EPOCHS = 10       
LR = 1e-4
WEIGHT_DECAY = 1e-4
IMG_SIZE = 384

# -----------------------------------------------------------
# 1. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„
# -----------------------------------------------------------
destination_path = os.path.join(BASE_DIR, "datasets")

# 1. ë°ì´í„°ì…‹ í´ë”ê°€ ì—†ìœ¼ë©´ -> ë‹¤ìš´ë¡œë“œ ë°›ê³  ì´ë™ì‹œí‚´
if not os.path.exists(destination_path):
    print("ğŸ“‚ ë°ì´í„°ì…‹ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (Kaggle Hub)...")
    try:
        # ë‹¤ìš´ë¡œë“œë¥¼ ì´ ì•ˆì—ì„œ ìˆ˜í–‰
        path = kagglehub.dataset_download("freedomfighter1290/wheat-disease")
        print(f"\nâœ… ë‹¤ìš´ë¡œë“œ ê²½ë¡œ: {path}")
        
        # Wheat_Disease í•˜ìœ„ í´ë” ì²˜ë¦¬
        path_with_subfolder = os.path.join(path, 'Wheat_Disease')
        if os.path.exists(path_with_subfolder):
            path = path_with_subfolder

        # í•„í„°ë§ ë¡œì§ (USE_FILTERED_CLASSESê°€ Trueì¼ ë•Œë§Œ)
        if USE_FILTERED_CLASSES:
            for split in SPLIT_FOLDERS:
                split_path = os.path.join(path, split)
                if os.path.exists(split_path):
                    for item in os.listdir(split_path):
                        item_path = os.path.join(split_path, item)
                        if os.path.isdir(item_path) and item not in ALLOWED_CLASSES:
                            shutil.rmtree(item_path)

        # í´ë” ì´ë™
        print("ğŸ“¦ ë°ì´í„°ì…‹ í´ë” ì´ë™ ë° ì •ë¦¬ ì¤‘...")
        shutil.move(path, destination_path)
        print(f"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ: {destination_path}")

    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ì´ë™ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ íŒ: 'kaggle.json' íŒŒì¼ í™•ì¸ ë˜ëŠ” ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
        exit()

# 2. ë°ì´í„°ì…‹ í´ë”ê°€ ì´ë¯¸ ìˆìœ¼ë©´ -> ë‹¤ìš´ë¡œë“œ ì•„ì˜ˆ ì•ˆ í•¨
else:
    print(f"âœ… ê¸°ì¡´ ë°ì´í„°ì…‹ í´ë”ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {destination_path}")


# -----------------------------------------------------------
# 2. ì „ì²˜ë¦¬ ë° DataLoader
# -----------------------------------------------------------
mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]

train_tf = transforms.Compose([
    transforms.Lambda(lambda x: x.convert("RGB")),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

val_tf = transforms.Compose([
    transforms.Lambda(lambda x: x.convert("RGB")),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

train_ds = datasets.ImageFolder(root=os.path.join(destination_path, "train"), transform=train_tf)
val_ds   = datasets.ImageFolder(root=os.path.join(destination_path, "validation"), transform=val_tf)

# Windowsì—ì„œëŠ” num_workers=0 ê¶Œì¥ (ì˜¤ë¥˜ ë°œìƒ ì‹œ)
train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

# í´ë˜ìŠ¤ ì •ë³´ ì €ì¥
class_names = train_ds.classes
with open(CLASS_PATH, "w", encoding="utf-8") as f:
    json.dump(class_names, f, ensure_ascii=False)

print(f"í´ë˜ìŠ¤ ëª©ë¡: {class_names}")

# -----------------------------------------------------------
# 3. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
# -----------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ì‚¬ìš© ì¥ì¹˜: {device}")

weights = models.EfficientNet_V2_S_Weights.DEFAULT
model = models.efficientnet_v2_s(weights=weights)

# Classifier ìˆ˜ì •
model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)

best_acc = 0.0
print("ğŸš€ í•™ìŠµ ì‹œì‘...")

for epoch in range(1, EPOCHS+1):
    model.train()
    total_loss, total = 0, 0
    train_correct = 0  # âœ… [ì¶”ê°€] í›ˆë ¨ ì •ë‹µ ê°œìˆ˜ ì´ˆê¸°í™”

    for batch_idx, (x, y) in enumerate(train_dl):
        x, y = x.to(device), y.to(device)
        
        optimizer.zero_grad()
        
        # ëª¨ë¸ ì˜ˆì¸¡ê°’ í•œ ë²ˆë§Œ ê³„ì‚°í•´ì„œ ë³€ìˆ˜ì— ì €ì¥
        outputs = model(x) 
        loss = criterion(outputs, y)
        
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * y.size(0)
        total += y.size(0)
        
        # âœ… [ì¶”ê°€] í›ˆë ¨ ì •í™•ë„ ê³„ì‚° ë¡œì§
        preds = outputs.argmax(dim=1)
        train_correct += (preds == y).sum().item()
        
        if batch_idx % 10 == 0:
            print(f"Epoch {epoch} [{batch_idx}/{len(train_dl)}] Loss: {loss.item():.4f}", end='\r')

    scheduler.step()

    # í›ˆë ¨ ì •í™•ë„ ê³„ì‚°
    train_acc = train_correct / total * 100 # âœ… [ì¶”ê°€]

    # ê²€ì¦ (Validation)
    model.eval()
    correct, val_total = 0, 0 # (ë³€ìˆ˜ëª… ê²¹ì¹˜ì§€ ì•Šê²Œ ì£¼ì˜)
    with torch.no_grad():
        for x, y in val_dl:
            x, y = x.to(device), y.to(device)
            preds = model(x).argmax(dim=1)
            correct += (preds == y).sum().item() # ì—¬ê¸°ëŠ” ê²€ì¦ ì •ë‹µ ê°œìˆ˜
            val_total += y.size(0)

    val_acc = correct / val_total * 100
    
    # âœ… [ìˆ˜ì •] ì¶œë ¥ë¬¸ì— Train Acc ì¶”ê°€
    print(f"\n[{epoch}/{EPOCHS}] Train Loss: {total_loss/total:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%")

    if val_acc > best_acc:
        best_acc = val_acc
        torch.save({
            "state_dict": model.state_dict(),
            "class_names": class_names,
            "model_type": "efficientnet_v2_s"
        }, CKPT_PATH)
        print(f"  ğŸ‰ ëª¨ë¸ ì €ì¥ë¨: {CKPT_PATH}")

print(f"\nâœ… ìµœì¢… í•™ìŠµ ì™„ë£Œ. ìµœê³  ì •í™•ë„: {best_acc:.2f}%")