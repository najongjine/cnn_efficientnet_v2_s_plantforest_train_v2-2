import os
import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, models
from PIL import Image
import matplotlib.pyplot as plt

# -----------------------------------------------------------
# 0. ì„¤ì • (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
# -----------------------------------------------------------
BASE_DIR = os.getcwd()
MODEL_SAVE_DIR = os.path.join(BASE_DIR, "my_models")
CKPT_PATH = os.path.join(MODEL_SAVE_DIR, "efficientnet_v2_s_plantforestdisease.pt")

IMG_SIZE = 384
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ (ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”)
TEST_IMAGE_PATH = r"C:\Users\najon\OneDrive\ì‚¬ì§„\plant4.png" 

# -----------------------------------------------------------
# 1. ëª¨ë¸ ë¡œë“œ ë° Grad-CAM í´ë˜ìŠ¤ ì •ì˜
# -----------------------------------------------------------
def load_trained_model(ckpt_path, device):
    if not os.path.exists(ckpt_path):
        raise FileNotFoundError(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}")

    print(f"ğŸ“‚ ëª¨ë¸ ë¡œë”© ì¤‘... ({ckpt_path})")
    checkpoint = torch.load(ckpt_path, map_location=device)
    class_names = checkpoint['class_names']
    
    model = models.efficientnet_v2_s(weights=None)
    in_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(in_features, len(class_names))
    model.load_state_dict(checkpoint['state_dict'])
    
    model.to(device)
    model.eval()
    return model, class_names

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        
        # Hook ë“±ë¡
        self.target_layer.register_forward_hook(self.save_activation)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def __call__(self, x, class_idx=None):
        # 1. Forward Pass
        outputs = self.model(x)
        if class_idx is None:
            class_idx = outputs.argmax(dim=1).item()
        
        # 2. Backward Pass (Gradients ê³„ì‚°)
        self.model.zero_grad()
        score = outputs[0, class_idx]
        score.backward()
        
        # 3. Grad-CAM ê³„ì‚°
        gradients = self.gradients[0]   # (C, H, W)
        activations = self.activations[0] # (C, H, W)
        
        # Global Average Pooling (ê°€ì¤‘ì¹˜ ê³„ì‚°)
        weights = torch.mean(gradients, dim=(1, 2))
        
        # ê°€ì¤‘ì¹˜ì™€ Feature Map ê²°í•©
        cam = torch.zeros(activations.shape[1:], dtype=torch.float32, device=DEVICE)
        for i, w in enumerate(weights):
            cam += w * activations[i]
            
        # ReLU ì ìš©
        cam = F.relu(cam)
        
        # ì •ê·œí™” (0~1)
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        
        return cam.cpu().detach().numpy(), class_idx, outputs

# -----------------------------------------------------------
# 2. ì‹œê°í™” í•¨ìˆ˜ë“¤
# -----------------------------------------------------------
def show_cam_on_image(img_path, mask, class_name, confidence):
    img = np.array(Image.open(img_path).convert("RGB"))
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    img = np.float32(img) / 255
    
    # Heatmap ìƒì„±
    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)
    heatmap = np.float32(heatmap) / 255
    heatmap = heatmap[..., ::-1] # BGR to RGB
    
    # ì›ë³¸ ì´ë¯¸ì§€ì™€ ê²¹ì¹˜ê¸°
    cam = heatmap * 0.4 + img * 0.6
    cam = cam / np.max(cam)
    
    plt.figure(figsize=(12, 5))
    
    # ì›ë³¸
    plt.subplot(1, 2, 1)
    plt.imshow(img)
    plt.title("Original Image")
    plt.axis('off')
    
    # Grad-CAM ê²°ê³¼
    plt.subplot(1, 2, 2)
    plt.imshow(np.uint8(255 * cam))
    plt.title(f"Grad-CAM\nPred: {class_name} ({confidence:.1f}%)")
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()

def visualize_feature_maps(model, img_tensor):
    # ì²« ë²ˆì§¸ í•©ì„±ê³± ì¸µ (Stem)ì˜ Feature Map ê°€ì ¸ì˜¤ê¸°
    # EfficientNet V2 Sì˜ êµ¬ì¡°ìƒ features[0]ì´ ì²« Conv ì¸µì…ë‹ˆë‹¤.
    with torch.no_grad():
        features = model.features[0](img_tensor)
    
    features = features[0].cpu().numpy() # (Batch, Channel, H, W) -> (Channel, H, W)
    
    # ì±„ë„ ì¤‘ ì• 16ê°œë§Œ ì‹œê°í™”
    num_channels = min(16, features.shape[0])
    
    plt.figure(figsize=(16, 8))
    for i in range(num_channels):
        plt.subplot(2, 8, i + 1)
        plt.imshow(features[i], cmap='viridis')
        plt.axis('off')
        plt.title(f"Ch {i}")
    
    plt.suptitle(f"Feature Maps (First Layer): {num_channels} channels", fontsize=16)
    plt.show()

# -----------------------------------------------------------
# 3. ë©”ì¸ ì‹¤í–‰
# -----------------------------------------------------------
if __name__ == "__main__":
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    mean = [0.485, 0.456, 0.406]
    std  = [0.229, 0.224, 0.225]
    transform = transforms.Compose([
        transforms.Lambda(lambda x: x.convert("RGB")),
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])

    if os.path.exists(TEST_IMAGE_PATH):
        # ëª¨ë¸ ë¡œë“œ
        model, class_names = load_trained_model(CKPT_PATH, DEVICE)
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(TEST_IMAGE_PATH)
        input_tensor = transform(image).unsqueeze(0).to(DEVICE)
        
        print("\nğŸ” [1] Feature Map ì‹œê°í™” (Low-level Features)...")
        visualize_feature_maps(model, input_tensor)
        
        print("\nğŸ” [2] Grad-CAM Heatmap ì‹œê°í™” (Decision Regions)...")
        # EfficientNet V2ì˜ ë§ˆì§€ë§‰ Conv ì¸µ: features[-1]
        target_layer = model.features[-1]
        grad_cam = GradCAM(model, target_layer)
        
        mask, class_idx, outputs = grad_cam(input_tensor)
        
        # ë§ˆìŠ¤í¬ í¬ê¸°ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë§ì¶¤
        mask = cv2.resize(mask, (IMG_SIZE, IMG_SIZE))
        
        # í™•ë¥  ê³„ì‚°
        probs = F.softmax(outputs, dim=1)
        confidence = probs[0][class_idx].item() * 100
        pred_class = class_names[class_idx]
        
        show_cam_on_image(TEST_IMAGE_PATH, mask, pred_class, confidence)
        
    else:
        print(f"âš ï¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TEST_IMAGE_PATH}")
        print("í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")